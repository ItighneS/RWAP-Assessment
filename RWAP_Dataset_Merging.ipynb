{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItighneS/RWAP-Assessment/blob/main/RWAP_Dataset_Merging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sDWF5jqskRH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28f42199",
        "outputId": "93825a1c-7685-44f9-e9fb-c14942f9b3b2"
      },
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b64c99a"
      },
      "source": [
        "After you run the previous cell and authorize access, run the next cell to load the datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading the Datasets"
      ],
      "metadata": {
        "id": "qV4VxLX86lGR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01e06853",
        "outputId": "4106ce65-614d-4dd5-da2f-9ace07d962a6"
      },
      "source": [
        "# Define the paths to the datasets\n",
        "dataset1_path = '/content/drive/MyDrive/RWAP/Dataset1.csv'\n",
        "dataset2_path = '/content/drive/MyDrive/RWAP/Dataset2.csv'\n",
        "\n",
        "# Load the datasets into pandas DataFrames\n",
        "try:\n",
        "    df_dataset1 = pd.read_csv(dataset1_path)\n",
        "    print(\"Dataset1 loaded successfully.\")\n",
        "    display(df_dataset1.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset1 not found at {dataset1_path}\")\n",
        "    df_dataset1 = None\n",
        "\n",
        "try:\n",
        "    df_dataset2 = pd.read_csv(dataset2_path)\n",
        "    print(\"Dataset2 loaded successfully.\")\n",
        "    display(df_dataset2.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset2 not found at {dataset2_path}\")\n",
        "    df_dataset2 = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset1 loaded successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Location Code    Real Property Asset Name Installation Name Owned or Leased  \\\n",
              "0        GA2338     THOMPSON BRIDGE RD BLDG               NaN               L   \n",
              "1        WI1771  345 WEST WASHINGTON AVENUE               NaN               L   \n",
              "2        MN1743         1301 1/2 7TH ST. NW               NaN               L   \n",
              "3        MD1008     WOODLAWN OFFICE COMPLEX               NaN               L   \n",
              "4        CO1890            466 TUCKER SREET               NaN               L   \n",
              "\n",
              "   GSA Region           Street Address         City State  Zip Code  \\\n",
              "0           4  2565 THOMPSON BRIDGE RD  GAINESVILLE    GA     30501   \n",
              "1           5     345 W WASHINGTON AVE      MADISON    WI     53703   \n",
              "2           5       1301 1/2 7TH ST NW    ROCHESTER    MN     55901   \n",
              "3           3         1718 WOODLAWN DR     WOODLAWN    MD     21207   \n",
              "4           8            466 TUCKER ST        CRAIG    CO     81625   \n",
              "\n",
              "    Latitude   Longitude  Building Rentable Square Feet  \\\n",
              "0  34.339030  -83.848641                        17844.0   \n",
              "1  43.071400  -89.387941                        10089.0   \n",
              "2  44.031849  -92.481598                         3041.0   \n",
              "3  39.314760  -76.737771                       160810.0   \n",
              "4  40.513620 -107.545000                         5000.0   \n",
              "\n",
              "   Available Square Feet  Construction Date  Congressional District  \\\n",
              "0                    NaN             2000.0                    1309   \n",
              "1                    NaN             2000.0                    5502   \n",
              "2                    NaN             2000.0                    2701   \n",
              "3                    NaN             2000.0                    2407   \n",
              "4                    NaN             2000.0                     803   \n",
              "\n",
              "  Congressional District Representative Name Building Status  \\\n",
              "0                               Andrew Clyde          Active   \n",
              "1                                 Mark Pocan          Active   \n",
              "2                               Brad Finstad          Active   \n",
              "3                               Kweisi Mfume          Active   \n",
              "4                             Lauren Boebert          Active   \n",
              "\n",
              "  Real Property Asset Type  \n",
              "0                 BUILDING  \n",
              "1                 BUILDING  \n",
              "2                 BUILDING  \n",
              "3                 BUILDING  \n",
              "4                 BUILDING  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04aa4977-12e1-411f-b4b9-79a4510ed57a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location Code</th>\n",
              "      <th>Real Property Asset Name</th>\n",
              "      <th>Installation Name</th>\n",
              "      <th>Owned or Leased</th>\n",
              "      <th>GSA Region</th>\n",
              "      <th>Street Address</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Zip Code</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Building Rentable Square Feet</th>\n",
              "      <th>Available Square Feet</th>\n",
              "      <th>Construction Date</th>\n",
              "      <th>Congressional District</th>\n",
              "      <th>Congressional District Representative Name</th>\n",
              "      <th>Building Status</th>\n",
              "      <th>Real Property Asset Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GA2338</td>\n",
              "      <td>THOMPSON BRIDGE RD BLDG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>4</td>\n",
              "      <td>2565 THOMPSON BRIDGE RD</td>\n",
              "      <td>GAINESVILLE</td>\n",
              "      <td>GA</td>\n",
              "      <td>30501</td>\n",
              "      <td>34.339030</td>\n",
              "      <td>-83.848641</td>\n",
              "      <td>17844.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1309</td>\n",
              "      <td>Andrew Clyde</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WI1771</td>\n",
              "      <td>345 WEST WASHINGTON AVENUE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>5</td>\n",
              "      <td>345 W WASHINGTON AVE</td>\n",
              "      <td>MADISON</td>\n",
              "      <td>WI</td>\n",
              "      <td>53703</td>\n",
              "      <td>43.071400</td>\n",
              "      <td>-89.387941</td>\n",
              "      <td>10089.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>5502</td>\n",
              "      <td>Mark Pocan</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MN1743</td>\n",
              "      <td>1301 1/2 7TH ST. NW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>5</td>\n",
              "      <td>1301 1/2 7TH ST NW</td>\n",
              "      <td>ROCHESTER</td>\n",
              "      <td>MN</td>\n",
              "      <td>55901</td>\n",
              "      <td>44.031849</td>\n",
              "      <td>-92.481598</td>\n",
              "      <td>3041.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2701</td>\n",
              "      <td>Brad Finstad</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MD1008</td>\n",
              "      <td>WOODLAWN OFFICE COMPLEX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>3</td>\n",
              "      <td>1718 WOODLAWN DR</td>\n",
              "      <td>WOODLAWN</td>\n",
              "      <td>MD</td>\n",
              "      <td>21207</td>\n",
              "      <td>39.314760</td>\n",
              "      <td>-76.737771</td>\n",
              "      <td>160810.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2407</td>\n",
              "      <td>Kweisi Mfume</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CO1890</td>\n",
              "      <td>466 TUCKER SREET</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>8</td>\n",
              "      <td>466 TUCKER ST</td>\n",
              "      <td>CRAIG</td>\n",
              "      <td>CO</td>\n",
              "      <td>81625</td>\n",
              "      <td>40.513620</td>\n",
              "      <td>-107.545000</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>803</td>\n",
              "      <td>Lauren Boebert</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04aa4977-12e1-411f-b4b9-79a4510ed57a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04aa4977-12e1-411f-b4b9-79a4510ed57a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04aa4977-12e1-411f-b4b9-79a4510ed57a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e2aff53b-9804-45fe-b19e-e893234e5d45\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2aff53b-9804-45fe-b19e-e893234e5d45')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e2aff53b-9804-45fe-b19e-e893234e5d45 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset2 loaded successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   RegionID  SizeRank  RegionName RegionType StateName State      City  \\\n",
              "0     91982         1       77494        zip        TX    TX      Katy   \n",
              "1     61148         2        8701        zip        NJ    NJ  Lakewood   \n",
              "2     91940         3       77449        zip        TX    TX      Katy   \n",
              "3     62080         4       11368        zip        NY    NY  New York   \n",
              "4     91733         5       77084        zip        TX    TX   Houston   \n",
              "\n",
              "                                   Metro        CountyName   31-01-2000  ...  \\\n",
              "0   Houston-The Woodlands-Sugar Land, TX  Fort Bend County  214937.7873  ...   \n",
              "1  New York-Newark-Jersey City, NY-NJ-PA      Ocean County  116810.6360  ...   \n",
              "2   Houston-The Woodlands-Sugar Land, TX     Harris County  105455.3185  ...   \n",
              "3  New York-Newark-Jersey City, NY-NJ-PA     Queens County  175466.1562  ...   \n",
              "4   Houston-The Woodlands-Sugar Land, TX     Harris County  104429.8830  ...   \n",
              "\n",
              "    31-10-2024   30-11-2024   31-12-2024   31-01-2025   28-02-2025  \\\n",
              "0  511217.8090  511954.1356  512382.5758  512816.5072  512487.4172   \n",
              "1  540520.8222  543510.7379  545285.8202  545849.9300  547812.3642   \n",
              "2  285966.9656  285165.7839  284424.4512  283803.7233  283169.6570   \n",
              "3  543312.8451  541859.7288  539178.0662  536665.5431  536533.0405   \n",
              "4  279339.6178  278729.0864  278383.5047  278136.3812  277726.8327   \n",
              "\n",
              "    31-03-2025   30-04-2025   31-05-2025   30-06-2025   31-07-2025  \n",
              "0  511561.2138  509731.4560  507492.0376  504842.2961  502726.3161  \n",
              "1  550152.4531  553512.2237  556393.3894  559017.4381  560869.5579  \n",
              "2  282323.9800  281349.6042  280532.3322  279516.0338  278559.7597  \n",
              "3  536184.6726  536070.6387  536466.7218  538555.2897  541336.1570  \n",
              "4  276853.0575  275794.7665  274885.5880  273866.1883  272937.6272  \n",
              "\n",
              "[5 rows x 316 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0f2b0c2-73ec-4173-82c6-c1c6fa1131ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RegionID</th>\n",
              "      <th>SizeRank</th>\n",
              "      <th>RegionName</th>\n",
              "      <th>RegionType</th>\n",
              "      <th>StateName</th>\n",
              "      <th>State</th>\n",
              "      <th>City</th>\n",
              "      <th>Metro</th>\n",
              "      <th>CountyName</th>\n",
              "      <th>31-01-2000</th>\n",
              "      <th>...</th>\n",
              "      <th>31-10-2024</th>\n",
              "      <th>30-11-2024</th>\n",
              "      <th>31-12-2024</th>\n",
              "      <th>31-01-2025</th>\n",
              "      <th>28-02-2025</th>\n",
              "      <th>31-03-2025</th>\n",
              "      <th>30-04-2025</th>\n",
              "      <th>31-05-2025</th>\n",
              "      <th>30-06-2025</th>\n",
              "      <th>31-07-2025</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91982</td>\n",
              "      <td>1</td>\n",
              "      <td>77494</td>\n",
              "      <td>zip</td>\n",
              "      <td>TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>Katy</td>\n",
              "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
              "      <td>Fort Bend County</td>\n",
              "      <td>214937.7873</td>\n",
              "      <td>...</td>\n",
              "      <td>511217.8090</td>\n",
              "      <td>511954.1356</td>\n",
              "      <td>512382.5758</td>\n",
              "      <td>512816.5072</td>\n",
              "      <td>512487.4172</td>\n",
              "      <td>511561.2138</td>\n",
              "      <td>509731.4560</td>\n",
              "      <td>507492.0376</td>\n",
              "      <td>504842.2961</td>\n",
              "      <td>502726.3161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61148</td>\n",
              "      <td>2</td>\n",
              "      <td>8701</td>\n",
              "      <td>zip</td>\n",
              "      <td>NJ</td>\n",
              "      <td>NJ</td>\n",
              "      <td>Lakewood</td>\n",
              "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
              "      <td>Ocean County</td>\n",
              "      <td>116810.6360</td>\n",
              "      <td>...</td>\n",
              "      <td>540520.8222</td>\n",
              "      <td>543510.7379</td>\n",
              "      <td>545285.8202</td>\n",
              "      <td>545849.9300</td>\n",
              "      <td>547812.3642</td>\n",
              "      <td>550152.4531</td>\n",
              "      <td>553512.2237</td>\n",
              "      <td>556393.3894</td>\n",
              "      <td>559017.4381</td>\n",
              "      <td>560869.5579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91940</td>\n",
              "      <td>3</td>\n",
              "      <td>77449</td>\n",
              "      <td>zip</td>\n",
              "      <td>TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>Katy</td>\n",
              "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
              "      <td>Harris County</td>\n",
              "      <td>105455.3185</td>\n",
              "      <td>...</td>\n",
              "      <td>285966.9656</td>\n",
              "      <td>285165.7839</td>\n",
              "      <td>284424.4512</td>\n",
              "      <td>283803.7233</td>\n",
              "      <td>283169.6570</td>\n",
              "      <td>282323.9800</td>\n",
              "      <td>281349.6042</td>\n",
              "      <td>280532.3322</td>\n",
              "      <td>279516.0338</td>\n",
              "      <td>278559.7597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62080</td>\n",
              "      <td>4</td>\n",
              "      <td>11368</td>\n",
              "      <td>zip</td>\n",
              "      <td>NY</td>\n",
              "      <td>NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
              "      <td>Queens County</td>\n",
              "      <td>175466.1562</td>\n",
              "      <td>...</td>\n",
              "      <td>543312.8451</td>\n",
              "      <td>541859.7288</td>\n",
              "      <td>539178.0662</td>\n",
              "      <td>536665.5431</td>\n",
              "      <td>536533.0405</td>\n",
              "      <td>536184.6726</td>\n",
              "      <td>536070.6387</td>\n",
              "      <td>536466.7218</td>\n",
              "      <td>538555.2897</td>\n",
              "      <td>541336.1570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91733</td>\n",
              "      <td>5</td>\n",
              "      <td>77084</td>\n",
              "      <td>zip</td>\n",
              "      <td>TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>Houston</td>\n",
              "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
              "      <td>Harris County</td>\n",
              "      <td>104429.8830</td>\n",
              "      <td>...</td>\n",
              "      <td>279339.6178</td>\n",
              "      <td>278729.0864</td>\n",
              "      <td>278383.5047</td>\n",
              "      <td>278136.3812</td>\n",
              "      <td>277726.8327</td>\n",
              "      <td>276853.0575</td>\n",
              "      <td>275794.7665</td>\n",
              "      <td>274885.5880</td>\n",
              "      <td>273866.1883</td>\n",
              "      <td>272937.6272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 316 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0f2b0c2-73ec-4173-82c6-c1c6fa1131ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0f2b0c2-73ec-4173-82c6-c1c6fa1131ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0f2b0c2-73ec-4173-82c6-c1c6fa1131ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2842271b-6514-4890-a28f-c5dffc83181f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2842271b-6514-4890-a28f-c5dffc83181f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2842271b-6514-4890-a28f-c5dffc83181f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "841a65d0"
      },
      "source": [
        "##Missing value Treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subtask:\n",
        "Create copies of `df_dataset1` and `df_dataset2` to perform preprocessing on."
      ],
      "metadata": {
        "id": "wOPjaGGt7Cgq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66349e92",
        "outputId": "aeaecdc2-bd7b-4d31-fe5b-97d49008c6b5"
      },
      "source": [
        "if df_dataset1 is not None:\n",
        "    df_dataset1_processed = df_dataset1.copy()\n",
        "    print(\"Created a copy of df_dataset1: df_dataset1_processed\")\n",
        "else:\n",
        "    print(\"df_dataset1 is not loaded, cannot create a copy.\")\n",
        "\n",
        "if df_dataset2 is not None:\n",
        "    df_dataset2_processed = df_dataset2.copy()\n",
        "    print(\"Created a copy of df_dataset2: df_dataset2_processed\")\n",
        "else:\n",
        "    print(\"df_dataset2 is not loaded, cannot create a copy.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a copy of df_dataset1: df_dataset1_processed\n",
            "Created a copy of df_dataset2: df_dataset2_processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b60d110f",
        "outputId": "4d3b9f26-0aae-466a-a659-4c67d3e12142"
      },
      "source": [
        "if 'df_dataset1_processed' in locals() and df_dataset1_processed is not None:\n",
        "    # Columns to drop (combined from both blocks)\n",
        "    columns_to_drop = [\n",
        "        'Location Code',\n",
        "        'Real Property Asset Name',\n",
        "        'Congressional District Representative Name',\n",
        "        'Installation Name',\n",
        "        'Available Square Feet'\n",
        "    ]\n",
        "\n",
        "    # Drop only those columns that exist\n",
        "    columns_exist = [col for col in columns_to_drop if col in df_dataset1_processed.columns]\n",
        "    if columns_exist:\n",
        "        df_dataset1_processed = df_dataset1_processed.drop(columns=columns_exist)\n",
        "        print(f\"Dropped columns: {columns_exist}\")\n",
        "    else:\n",
        "        print(\"None of the specified columns were found in df_dataset1_processed.\")\n",
        "\n",
        "    # Print summary after dropping\n",
        "    print(\"\\n--- Columns in df_dataset1_processed after dropping ---\")\n",
        "    print(df_dataset1_processed.columns.tolist())\n",
        "\n",
        "    print(\"\\n--- Missing Values in df_dataset1_processed after dropping columns ---\")\n",
        "    print(df_dataset1_processed.isnull().sum())\n",
        "else:\n",
        "    print(\"df_dataset1_processed is not available. Please ensure previous steps were completed.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped columns: ['Location Code', 'Real Property Asset Name', 'Congressional District Representative Name', 'Installation Name', 'Available Square Feet']\n",
            "\n",
            "--- Columns in df_dataset1_processed after dropping ---\n",
            "['Owned or Leased', 'GSA Region', 'Street Address', 'City', 'State', 'Zip Code', 'Latitude', 'Longitude', 'Building Rentable Square Feet', 'Construction Date', 'Congressional District', 'Building Status', 'Real Property Asset Type']\n",
            "\n",
            "--- Missing Values in df_dataset1_processed after dropping columns ---\n",
            "Owned or Leased                   0\n",
            "GSA Region                        0\n",
            "Street Address                    0\n",
            "City                              0\n",
            "State                             0\n",
            "Zip Code                          0\n",
            "Latitude                          0\n",
            "Longitude                         0\n",
            "Building Rentable Square Feet     0\n",
            "Construction Date                50\n",
            "Congressional District            0\n",
            "Building Status                   0\n",
            "Real Property Asset Type          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d313239"
      },
      "source": [
        "\n",
        "\n",
        "### Subtask: Feature Build\n",
        "Create 'Building Age' column based on 'Construction Date'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "bff70687",
        "outputId": "42de7222-860d-4e1c-e200-300a0a11d679"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "if 'df_dataset1_processed' in locals() and df_dataset1_processed is not None:\n",
        "    # Get the current year\n",
        "    current_year = datetime.now().year\n",
        "\n",
        "    # Calculate 'Building Age', preserving NaN values\n",
        "    # The subtraction will automatically result in NaN if 'Construction Date' is NaN\n",
        "    df_dataset1_processed['Building Age'] = current_year - df_dataset1_processed['Construction Date']\n",
        "\n",
        "    print(\"Added 'Building Age' column to df_dataset1_processed.\")\n",
        "\n",
        "    print(\"\\n--- Head of df_dataset1_processed with 'Building Age' ---\")\n",
        "    display(df_dataset1_processed.head())\n",
        "\n",
        "    print(\"\\n--- Info of df_dataset1_processed with 'Building Age' ---\")\n",
        "    df_dataset1_processed.info()\n",
        "\n",
        "else:\n",
        "    print(\"df_dataset1_processed is not available. Please ensure previous steps were completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 'Building Age' column to df_dataset1_processed.\n",
            "\n",
            "--- Head of df_dataset1_processed with 'Building Age' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Owned or Leased  GSA Region           Street Address         City State  \\\n",
              "0               L           4  2565 THOMPSON BRIDGE RD  GAINESVILLE    GA   \n",
              "1               L           5     345 W WASHINGTON AVE      MADISON    WI   \n",
              "2               L           5       1301 1/2 7TH ST NW    ROCHESTER    MN   \n",
              "3               L           3         1718 WOODLAWN DR     WOODLAWN    MD   \n",
              "4               L           8            466 TUCKER ST        CRAIG    CO   \n",
              "\n",
              "   Zip Code   Latitude   Longitude  Building Rentable Square Feet  \\\n",
              "0     30501  34.339030  -83.848641                        17844.0   \n",
              "1     53703  43.071400  -89.387941                        10089.0   \n",
              "2     55901  44.031849  -92.481598                         3041.0   \n",
              "3     21207  39.314760  -76.737771                       160810.0   \n",
              "4     81625  40.513620 -107.545000                         5000.0   \n",
              "\n",
              "   Construction Date  Congressional District Building Status  \\\n",
              "0             2000.0                    1309          Active   \n",
              "1             2000.0                    5502          Active   \n",
              "2             2000.0                    2701          Active   \n",
              "3             2000.0                    2407          Active   \n",
              "4             2000.0                     803          Active   \n",
              "\n",
              "  Real Property Asset Type  Building Age  \n",
              "0                 BUILDING          25.0  \n",
              "1                 BUILDING          25.0  \n",
              "2                 BUILDING          25.0  \n",
              "3                 BUILDING          25.0  \n",
              "4                 BUILDING          25.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b8c8fd3-e84a-4b48-ac46-a1879da81bab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Owned or Leased</th>\n",
              "      <th>GSA Region</th>\n",
              "      <th>Street Address</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Zip Code</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Building Rentable Square Feet</th>\n",
              "      <th>Construction Date</th>\n",
              "      <th>Congressional District</th>\n",
              "      <th>Building Status</th>\n",
              "      <th>Real Property Asset Type</th>\n",
              "      <th>Building Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L</td>\n",
              "      <td>4</td>\n",
              "      <td>2565 THOMPSON BRIDGE RD</td>\n",
              "      <td>GAINESVILLE</td>\n",
              "      <td>GA</td>\n",
              "      <td>30501</td>\n",
              "      <td>34.339030</td>\n",
              "      <td>-83.848641</td>\n",
              "      <td>17844.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1309</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L</td>\n",
              "      <td>5</td>\n",
              "      <td>345 W WASHINGTON AVE</td>\n",
              "      <td>MADISON</td>\n",
              "      <td>WI</td>\n",
              "      <td>53703</td>\n",
              "      <td>43.071400</td>\n",
              "      <td>-89.387941</td>\n",
              "      <td>10089.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>5502</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L</td>\n",
              "      <td>5</td>\n",
              "      <td>1301 1/2 7TH ST NW</td>\n",
              "      <td>ROCHESTER</td>\n",
              "      <td>MN</td>\n",
              "      <td>55901</td>\n",
              "      <td>44.031849</td>\n",
              "      <td>-92.481598</td>\n",
              "      <td>3041.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2701</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L</td>\n",
              "      <td>3</td>\n",
              "      <td>1718 WOODLAWN DR</td>\n",
              "      <td>WOODLAWN</td>\n",
              "      <td>MD</td>\n",
              "      <td>21207</td>\n",
              "      <td>39.314760</td>\n",
              "      <td>-76.737771</td>\n",
              "      <td>160810.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2407</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L</td>\n",
              "      <td>8</td>\n",
              "      <td>466 TUCKER ST</td>\n",
              "      <td>CRAIG</td>\n",
              "      <td>CO</td>\n",
              "      <td>81625</td>\n",
              "      <td>40.513620</td>\n",
              "      <td>-107.545000</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>803</td>\n",
              "      <td>Active</td>\n",
              "      <td>BUILDING</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8c8fd3-e84a-4b48-ac46-a1879da81bab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b8c8fd3-e84a-4b48-ac46-a1879da81bab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b8c8fd3-e84a-4b48-ac46-a1879da81bab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b5d9895-c74c-40e4-8930-88ae20a918d7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b5d9895-c74c-40e4-8930-88ae20a918d7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b5d9895-c74c-40e4-8930-88ae20a918d7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"df_dataset1_processed is not available\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Owned or Leased\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"L\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GSA Region\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Street Address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"345 W WASHINGTON AVE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MADISON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"WI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Zip Code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23706,\n        \"min\": 21207,\n        \"max\": 81625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          53703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8126870747016546,\n        \"min\": 34.33903,\n        \"max\": 44.0318491,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          43.0714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.490059870192157,\n        \"min\": -107.545,\n        \"max\": -76.737771,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -89.387941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Building Rentable Square Feet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68134.99744404487,\n        \"min\": 3041.0,\n        \"max\": 160810.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10089.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Construction Date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 2000.0,\n        \"max\": 2000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Congressional District\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1826,\n        \"min\": 803,\n        \"max\": 5502,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Building Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Active\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Real Property Asset Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BUILDING\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Building Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 25.0,\n        \"max\": 25.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          25.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Info of df_dataset1_processed with 'Building Age' ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8652 entries, 0 to 8651\n",
            "Data columns (total 14 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Owned or Leased                8652 non-null   object \n",
            " 1   GSA Region                     8652 non-null   int64  \n",
            " 2   Street Address                 8652 non-null   object \n",
            " 3   City                           8652 non-null   object \n",
            " 4   State                          8652 non-null   object \n",
            " 5   Zip Code                       8652 non-null   int64  \n",
            " 6   Latitude                       8652 non-null   float64\n",
            " 7   Longitude                      8652 non-null   float64\n",
            " 8   Building Rentable Square Feet  8652 non-null   float64\n",
            " 9   Construction Date              8602 non-null   float64\n",
            " 10  Congressional District         8652 non-null   int64  \n",
            " 11  Building Status                8652 non-null   object \n",
            " 12  Real Property Asset Type       8652 non-null   object \n",
            " 13  Building Age                   8602 non-null   float64\n",
            "dtypes: float64(5), int64(3), object(6)\n",
            "memory usage: 946.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3af9779"
      },
      "source": [
        "### Subtask:Handle Categorical Variables (df_dataset1)\n",
        "\n",
        "Identify and prepare categorical variables in `df_dataset1_processed` for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f955d7c9",
        "outputId": "7da87a32-f510-4dfc-837c-229fa0d95aef"
      },
      "source": [
        "if 'df_dataset1_processed' in locals() and df_dataset1_processed is not None:\n",
        "    print(\"--- Value Counts for Categorical Columns in df_dataset1_processed ---\")\n",
        "\n",
        "    # Identify categorical columns (excluding those likely to be unique identifiers or addresses)\n",
        "    categorical_cols = [\n",
        "        'Owned or Leased',\n",
        "        'GSA Region',\n",
        "        'State', 'City',\n",
        "        'Congressional District',\n",
        "        'Building Status',\n",
        "        'Real Property Asset Type'\n",
        "        ]\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        if col in df_dataset1_processed.columns:\n",
        "            print(f\"\\n--- Value Counts for {col} ---\")\n",
        "            print(df_dataset1_processed[col].value_counts())\n",
        "        else:\n",
        "            print(f\"\\nColumn '{col}' not found in df_dataset1_processed.\")\n",
        "\n",
        "    print(\"\\nBased on these value counts, you can decide which categorical columns to encode and which encoding method to use.\")\n",
        "\n",
        "else:\n",
        "    print(\"df_dataset1_processed is not available. Please ensure previous steps were completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Value Counts for Categorical Columns in df_dataset1_processed ---\n",
            "\n",
            "--- Value Counts for Owned or Leased ---\n",
            "Owned or Leased\n",
            "L    6850\n",
            "F    1802\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Value Counts for GSA Region ---\n",
            "GSA Region\n",
            "4     1390\n",
            "7     1387\n",
            "9     1058\n",
            "5      982\n",
            "3      778\n",
            "8      676\n",
            "11     595\n",
            "2      521\n",
            "10     478\n",
            "1      395\n",
            "6      392\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Value Counts for State ---\n",
            "State\n",
            "TX    908\n",
            "CA    733\n",
            "FL    401\n",
            "NY    358\n",
            "VA    348\n",
            "MD    311\n",
            "DC    278\n",
            "CO    242\n",
            "PA    240\n",
            "IL    230\n",
            "MI    220\n",
            "WA    211\n",
            "NC    205\n",
            "GA    202\n",
            "AZ    198\n",
            "MO    194\n",
            "OH    189\n",
            "TN    157\n",
            "MT    141\n",
            "NM    139\n",
            "NJ    138\n",
            "LA    138\n",
            "IN    137\n",
            "AL    123\n",
            "OK    120\n",
            "KY    117\n",
            "MA    115\n",
            "WI    109\n",
            "WV    101\n",
            "AK    101\n",
            "OR    100\n",
            "UT    100\n",
            "MN     97\n",
            "MS     93\n",
            "SC     92\n",
            "ME     90\n",
            "AR     82\n",
            "VT     79\n",
            "PR     75\n",
            "IA     75\n",
            "ND     74\n",
            "KS     69\n",
            "SD     69\n",
            "ID     66\n",
            "NV     60\n",
            "NE     54\n",
            "CT     52\n",
            "WY     50\n",
            "HI     46\n",
            "NH     37\n",
            "DE     32\n",
            "RI     22\n",
            "VI     13\n",
            "GU      9\n",
            "MP      7\n",
            "AS      5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Value Counts for City ---\n",
            "City\n",
            "WASHINGTON          280\n",
            "EL PASO              86\n",
            "LAREDO               86\n",
            "LAKEWOOD             76\n",
            "SAN DIEGO            66\n",
            "                   ... \n",
            "NORTH RIVERSIDE       1\n",
            "SMITHFIELD            1\n",
            "WEST BEND             1\n",
            "ESTCOURT STATION      1\n",
            "HUMACAO               1\n",
            "Name: count, Length: 1949, dtype: int64\n",
            "\n",
            "--- Value Counts for Congressional District ---\n",
            "Congressional District\n",
            "1198    278\n",
            "4823    135\n",
            "4834    109\n",
            "4828    105\n",
            "200     101\n",
            "       ... \n",
            "1709      2\n",
            "4826      1\n",
            "3609      1\n",
            "1211      1\n",
            "4201      1\n",
            "Name: count, Length: 439, dtype: int64\n",
            "\n",
            "--- Value Counts for Building Status ---\n",
            "Building Status\n",
            "Active            8588\n",
            "Excess              51\n",
            "Decommissioned      13\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Value Counts for Real Property Asset Type ---\n",
            "Real Property Asset Type\n",
            "BUILDING     8271\n",
            "STRUCTURE     331\n",
            "LAND           50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Based on these value counts, you can decide which categorical columns to encode and which encoding method to use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df_dataset2_processed' in locals() and df_dataset2_processed is not None:\n",
        "    print(\"--- Dropping specified columns from df_dataset2_processed ---\")\n",
        "    columns_to_drop = ['RegionID', 'RegionType', 'StateName']\n",
        "    columns_to_drop_exist = [col for col in columns_to_drop if col in df_dataset2_processed.columns]\n",
        "\n",
        "    if columns_to_drop_exist:\n",
        "        df_dataset2_processed = df_dataset2_processed.drop(columns=columns_to_drop_exist)\n",
        "        print(f\"Dropped columns: {columns_to_drop_exist}\")\n",
        "    else:\n",
        "        print(\"Specified columns not found in df_dataset2_processed.\")\n",
        "\n",
        "    print(\"\\n--- Columns in df_dataset2_processed after dropping ---\")\n",
        "    print(df_dataset2_processed.columns)\n",
        "\n",
        "else:\n",
        "    print(\"df_dataset2_processed is not available. Please ensure previous steps were completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZknvCUS0GDV9",
        "outputId": "ac97c130-f0ae-45a9-e1aa-57fec8bf1a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dropping specified columns from df_dataset2_processed ---\n",
            "Dropped columns: ['RegionID', 'RegionType', 'StateName']\n",
            "\n",
            "--- Columns in df_dataset2_processed after dropping ---\n",
            "Index(['SizeRank', 'RegionName', 'State', 'City', 'Metro', 'CountyName',\n",
            "       '31-01-2000', '29-02-2000', '31-03-2000', '30-04-2000',\n",
            "       ...\n",
            "       '31-10-2024', '30-11-2024', '31-12-2024', '31-01-2025', '28-02-2025',\n",
            "       '31-03-2025', '30-04-2025', '31-05-2025', '30-06-2025', '31-07-2025'],\n",
            "      dtype='object', length=313)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def encode_categorical_columns_consistently(\n",
        "    df1, df2, columns_df1, columns_df2,\n",
        "    mapping_file_path_df1=\"encoding_mappings_dataset1.json\",\n",
        "    mapping_file_path_df2=\"encoding_mappings_dataset2.json\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Encode categorical columns in two datasets consistently.\n",
        "    Saves separate mapping JSONs for dataset1 and dataset2.\n",
        "\n",
        "    Returns:\n",
        "        df1_encoded, df2_encoded\n",
        "    \"\"\"\n",
        "    encoding_mappings_df1 = {}\n",
        "    encoding_mappings_df2 = {}\n",
        "\n",
        "    # Take union of all columns needing encoding\n",
        "    all_columns = set(columns_df1).union(set(columns_df2))\n",
        "\n",
        "    for col in all_columns:\n",
        "        # Collect unique values from both datasets (ignoring NaNs)\n",
        "        unique_values = set()\n",
        "        if col in df1.columns:\n",
        "            unique_values.update(df1[col].dropna().unique())\n",
        "        if col in df2.columns:\n",
        "            unique_values.update(df2[col].dropna().unique())\n",
        "\n",
        "        # Sort to assign consistent numeric labels\n",
        "        sorted_values = sorted(unique_values, key=lambda x: str(x))\n",
        "        value_map = {str(val): int(idx) for idx, val in enumerate(sorted_values)}\n",
        "\n",
        "        # Apply mapping to each dataset if column exists\n",
        "        if col in df1.columns:\n",
        "            df1[col] = df1[col].map(lambda x: value_map.get(str(x)) if pd.notnull(x) else x)\n",
        "            if col in columns_df1:\n",
        "                encoding_mappings_df1[col] = value_map\n",
        "\n",
        "        if col in df2.columns:\n",
        "            df2[col] = df2[col].map(lambda x: value_map.get(str(x)) if pd.notnull(x) else x)\n",
        "            if col in columns_df2:\n",
        "                encoding_mappings_df2[col] = value_map\n",
        "\n",
        "        print(f\"Encoded column '{col}' consistently across datasets.\")\n",
        "\n",
        "    # Save mappings\n",
        "    with open(mapping_file_path_df1, \"w\") as f1:\n",
        "        json.dump(encoding_mappings_df1, f1, indent=4)\n",
        "        print(f\"Dataset1 encoding mapping saved to '{mapping_file_path_df1}'\")\n",
        "\n",
        "    with open(mapping_file_path_df2, \"w\") as f2:\n",
        "        json.dump(encoding_mappings_df2, f2, indent=4)\n",
        "        print(f\"Dataset2 encoding mapping saved to '{mapping_file_path_df2}'\")\n",
        "\n",
        "    return df1, df2\n",
        "\n",
        "# Updated column lists\n",
        "label_encode_cols_df1 = [\n",
        "    'Owned or Leased', 'GSA Region', 'State', 'Congressional District',\n",
        "    'City', 'Building Status', 'Real Property Asset Type'\n",
        "]\n",
        "\n",
        "label_encode_cols_df2 = [\n",
        "    'State', 'City', 'Metro', 'CountyName'\n",
        "]\n",
        "\n",
        "# Encode consistently\n",
        "df_dataset1_processed, df_dataset2_processed = encode_categorical_columns_consistently(\n",
        "    df_dataset1_processed, df_dataset2_processed,\n",
        "    label_encode_cols_df1, label_encode_cols_df2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ta4uw4UGVU9",
        "outputId": "6b18ab1a-49b3-40e2-9efd-b9275992bae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded column 'CountyName' consistently across datasets.\n",
            "Encoded column 'Owned or Leased' consistently across datasets.\n",
            "Encoded column 'State' consistently across datasets.\n",
            "Encoded column 'City' consistently across datasets.\n",
            "Encoded column 'Metro' consistently across datasets.\n",
            "Encoded column 'GSA Region' consistently across datasets.\n",
            "Encoded column 'Congressional District' consistently across datasets.\n",
            "Encoded column 'Real Property Asset Type' consistently across datasets.\n",
            "Encoded column 'Building Status' consistently across datasets.\n",
            "Dataset1 encoding mapping saved to 'encoding_mappings_dataset1.json'\n",
            "Dataset2 encoding mapping saved to 'encoding_mappings_dataset2.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec3f0e6a",
        "outputId": "1aa8b286-2b7c-4658-9b54-b6555df83fb0"
      },
      "source": [
        "if 'df_dataset1_processed' in locals() and df_dataset1_processed is not None:\n",
        "    print(\"--- Columns in df_dataset1_processed ---\")\n",
        "    print(df_dataset1_processed.columns.tolist())\n",
        "else:\n",
        "    print(\"df_dataset1_processed is not available.\")\n",
        "\n",
        "if 'df_dataset2_processed' in locals() and df_dataset2_processed is not None:\n",
        "    print(\"\\n--- Columns in df_dataset2_processed ---\")\n",
        "    print(df_dataset2_processed.columns.tolist())\n",
        "else:\n",
        "    print(\"df_dataset2_processed is not available.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Columns in df_dataset1_processed ---\n",
            "['Owned or Leased', 'GSA Region', 'Street Address', 'City', 'State', 'Zip Code', 'Latitude', 'Longitude', 'Building Rentable Square Feet', 'Construction Date', 'Congressional District', 'Building Status', 'Real Property Asset Type', 'Building Age']\n",
            "\n",
            "--- Columns in df_dataset2_processed ---\n",
            "['SizeRank', 'RegionName', 'State', 'City', 'Metro', 'CountyName', '31-01-2000', '29-02-2000', '31-03-2000', '30-04-2000', '31-05-2000', '30-06-2000', '31-07-2000', '31-08-2000', '30-09-2000', '31-10-2000', '30-11-2000', '31-12-2000', '31-01-2001', '28-02-2001', '31-03-2001', '30-04-2001', '31-05-2001', '30-06-2001', '31-07-2001', '31-08-2001', '30-09-2001', '31-10-2001', '30-11-2001', '31-12-2001', '31-01-2002', '28-02-2002', '31-03-2002', '30-04-2002', '31-05-2002', '30-06-2002', '31-07-2002', '31-08-2002', '30-09-2002', '31-10-2002', '30-11-2002', '31-12-2002', '31-01-2003', '28-02-2003', '31-03-2003', '30-04-2003', '31-05-2003', '30-06-2003', '31-07-2003', '31-08-2003', '30-09-2003', '31-10-2003', '30-11-2003', '31-12-2003', '31-01-2004', '29-02-2004', '31-03-2004', '30-04-2004', '31-05-2004', '30-06-2004', '31-07-2004', '31-08-2004', '30-09-2004', '31-10-2004', '30-11-2004', '31-12-2004', '31-01-2005', '28-02-2005', '31-03-2005', '30-04-2005', '31-05-2005', '30-06-2005', '31-07-2005', '31-08-2005', '30-09-2005', '31-10-2005', '30-11-2005', '31-12-2005', '31-01-2006', '28-02-2006', '31-03-2006', '30-04-2006', '31-05-2006', '30-06-2006', '31-07-2006', '31-08-2006', '30-09-2006', '31-10-2006', '30-11-2006', '31-12-2006', '31-01-2007', '28-02-2007', '31-03-2007', '30-04-2007', '31-05-2007', '30-06-2007', '31-07-2007', '31-08-2007', '30-09-2007', '31-10-2007', '30-11-2007', '31-12-2007', '31-01-2008', '29-02-2008', '31-03-2008', '30-04-2008', '31-05-2008', '30-06-2008', '31-07-2008', '31-08-2008', '30-09-2008', '31-10-2008', '30-11-2008', '31-12-2008', '31-01-2009', '28-02-2009', '31-03-2009', '30-04-2009', '31-05-2009', '30-06-2009', '31-07-2009', '31-08-2009', '30-09-2009', '31-10-2009', '30-11-2009', '31-12-2009', '31-01-2010', '28-02-2010', '31-03-2010', '30-04-2010', '31-05-2010', '30-06-2010', '31-07-2010', '31-08-2010', '30-09-2010', '31-10-2010', '30-11-2010', '31-12-2010', '31-01-2011', '28-02-2011', '31-03-2011', '30-04-2011', '31-05-2011', '30-06-2011', '31-07-2011', '31-08-2011', '30-09-2011', '31-10-2011', '30-11-2011', '31-12-2011', '31-01-2012', '29-02-2012', '31-03-2012', '30-04-2012', '31-05-2012', '30-06-2012', '31-07-2012', '31-08-2012', '30-09-2012', '31-10-2012', '30-11-2012', '31-12-2012', '31-01-2013', '28-02-2013', '31-03-2013', '30-04-2013', '31-05-2013', '30-06-2013', '31-07-2013', '31-08-2013', '30-09-2013', '31-10-2013', '30-11-2013', '31-12-2013', '31-01-2014', '28-02-2014', '31-03-2014', '30-04-2014', '31-05-2014', '30-06-2014', '31-07-2014', '31-08-2014', '30-09-2014', '31-10-2014', '30-11-2014', '31-12-2014', '31-01-2015', '28-02-2015', '31-03-2015', '30-04-2015', '31-05-2015', '30-06-2015', '31-07-2015', '31-08-2015', '30-09-2015', '31-10-2015', '30-11-2015', '31-12-2015', '31-01-2016', '29-02-2016', '31-03-2016', '30-04-2016', '31-05-2016', '30-06-2016', '31-07-2016', '31-08-2016', '30-09-2016', '31-10-2016', '30-11-2016', '31-12-2016', '31-01-2017', '28-02-2017', '31-03-2017', '30-04-2017', '31-05-2017', '30-06-2017', '31-07-2017', '31-08-2017', '30-09-2017', '31-10-2017', '30-11-2017', '31-12-2017', '31-01-2018', '28-02-2018', '31-03-2018', '30-04-2018', '31-05-2018', '30-06-2018', '31-07-2018', '31-08-2018', '30-09-2018', '31-10-2018', '30-11-2018', '31-12-2018', '31-01-2019', '28-02-2019', '31-03-2019', '30-04-2019', '31-05-2019', '30-06-2019', '31-07-2019', '31-08-2019', '30-09-2019', '31-10-2019', '30-11-2019', '31-12-2019', '31-01-2020', '29-02-2020', '31-03-2020', '30-04-2020', '31-05-2020', '30-06-2020', '31-07-2020', '31-08-2020', '30-09-2020', '31-10-2020', '30-11-2020', '31-12-2020', '31-01-2021', '28-02-2021', '31-03-2021', '30-04-2021', '31-05-2021', '30-06-2021', '31-07-2021', '31-08-2021', '30-09-2021', '31-10-2021', '30-11-2021', '31-12-2021', '31-01-2022', '28-02-2022', '31-03-2022', '30-04-2022', '31-05-2022', '30-06-2022', '31-07-2022', '31-08-2022', '30-09-2022', '31-10-2022', '30-11-2022', '31-12-2022', '31-01-2023', '28-02-2023', '31-03-2023', '30-04-2023', '31-05-2023', '30-06-2023', '31-07-2023', '31-08-2023', '30-09-2023', '31-10-2023', '30-11-2023', '31-12-2023', '31-01-2024', '29-02-2024', '31-03-2024', '30-04-2024', '31-05-2024', '30-06-2024', '31-07-2024', '31-08-2024', '30-09-2024', '31-10-2024', '30-11-2024', '31-12-2024', '31-01-2025', '28-02-2025', '31-03-2025', '30-04-2025', '31-05-2025', '30-06-2025', '31-07-2025']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task : Primary Merge using ZipCode and RegionName"
      ],
      "metadata": {
        "id": "rc2vNxlZ7QJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Step 0: Clean up any leftover engineered columns ---\n",
        "for col in df_dataset1_processed.columns:\n",
        "    if \"city_state_clean\" in col:\n",
        "        df_dataset1_processed = df_dataset1_processed.drop(columns=[col])\n",
        "\n",
        "for col in df_dataset2_processed.columns:\n",
        "    if \"city_state_clean\" in col:\n",
        "        df_dataset2_processed = df_dataset2_processed.drop(columns=[col])\n",
        "\n",
        "# --- Step 1: Ensure Zip columns are strings for merging ---\n",
        "df_dataset1_processed[\"Zip Code\"] = df_dataset1_processed[\"Zip Code\"].astype(str)\n",
        "df_dataset2_processed[\"RegionName\"] = df_dataset2_processed[\"RegionName\"].astype(str)\n",
        "\n",
        "# --- Step 2: Primary merge on Zip Code ---\n",
        "merged_zip = pd.merge(\n",
        "    df_dataset1_processed,\n",
        "    df_dataset2_processed,\n",
        "    left_on=\"Zip Code\",\n",
        "    right_on=\"RegionName\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"_d1\", \"_d2\")\n",
        ")\n",
        "\n",
        "print(\"--- Performing primary merge on Zip Code ---\")\n",
        "\n",
        "# Check if SizeRank exists before filtering unmatched\n",
        "if \"SizeRank\" in merged_zip.columns:\n",
        "    unmatched_zip = merged_zip[merged_zip[\"SizeRank\"].isnull()].copy()\n",
        "    print(f\"{len(unmatched_zip)} rows from dataset1 did not find a match on Zip Code.\")\n",
        "else:\n",
        "    unmatched_zip = pd.DataFrame()  # fallback empty DataFrame\n",
        "    print(\"Warning: 'SizeRank' column not found in dataset2; cannot detect unmatched rows.\")\n",
        "\n",
        "# Optionally reset index\n",
        "merged_zip.reset_index(drop=True, inplace=True)\n",
        "unmatched_zip.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP6Hq6nZr-pv",
        "outputId": "4b04d33b-469d-42d5-cff4-56d5eb046969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Performing primary merge on Zip Code ---\n",
            "616 rows from dataset1 did not find a match on Zip Code.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task: Secondary Merge using City + State"
      ],
      "metadata": {
        "id": "59f0JoPJ7Ybu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### --- Step 3: Secondary merge on City+State for unmatched Zip ---\n",
        "\n",
        "# Work on a copy to avoid SettingWithCopyWarning\n",
        "unmatched_zip = unmatched_zip.copy()\n",
        "\n",
        "# Ensure City/State columns exist in both datasets\n",
        "for col in [\"City_d1\", \"State_d1\"]:\n",
        "    if col not in unmatched_zip.columns:\n",
        "        unmatched_zip[col] = \"\"  # fallback empty string if missing\n",
        "\n",
        "for col in [\"City\", \"State\"]:\n",
        "    if col not in df_dataset2_processed.columns:\n",
        "        df_dataset2_processed[col] = \"\"\n",
        "\n",
        "# Create clean city_state keys for dataset1\n",
        "unmatched_zip[\"city_state_clean_d1\"] = (\n",
        "    unmatched_zip[\"City_d1\"].astype(str).str.strip().str.lower() + \", \" +\n",
        "    unmatched_zip[\"State_d1\"].astype(str).str.strip().str.lower()\n",
        ")\n",
        "\n",
        "# Create clean city_state keys for dataset2\n",
        "df_dataset2_processed[\"city_state_clean_d2\"] = (\n",
        "    df_dataset2_processed[\"City\"].astype(str).str.strip().str.lower() + \", \" +\n",
        "    df_dataset2_processed[\"State\"].astype(str).str.strip().str.lower()\n",
        ")\n",
        "\n",
        "# Perform secondary merge\n",
        "merged_city = pd.merge(\n",
        "    unmatched_zip,\n",
        "    df_dataset2_processed,\n",
        "    left_on=\"city_state_clean_d1\",\n",
        "    right_on=\"city_state_clean_d2\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"_d1\", \"_d2\")\n",
        ")\n",
        "\n",
        "print(\"\\n--- Performing secondary merge on City+State ---\")\n",
        "\n",
        "# Detect which RegionName belongs to dataset2\n",
        "region_candidates = [c for c in merged_city.columns if \"RegionName\" in c]\n",
        "print(\"RegionName candidates after merge:\", region_candidates)\n",
        "\n",
        "# Select the right column (dataset2 side)\n",
        "region_col = next((c for c in region_candidates if c.endswith(\"_d2\") or c.endswith(\"_city\")), None)\n",
        "if region_col is None:\n",
        "    region_col = \"RegionName\"  # fallback\n",
        "\n",
        "# Rows still unmatched after City+State merge\n",
        "unmatched_city = merged_city[merged_city[region_col].isnull()].copy()\n",
        "print(f\"{len(unmatched_city)} rows from dataset1 still unmatched after City+State merge.\")\n",
        "\n",
        "# Optional: reset index for convenience\n",
        "merged_city.reset_index(drop=True, inplace=True)\n",
        "unmatched_city.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE0O0ukztY38",
        "outputId": "d18e167a-a789-4d91-8fb2-86e419dee075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Performing secondary merge on City+State ---\n",
            "RegionName candidates after merge: ['RegionName_d1', 'RegionName_d2']\n",
            "616 rows from dataset1 still unmatched after City+State merge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### --- Step 4: Consolidate matches from Zip and City+State ---\n",
        "\n",
        "# Primary merge matches (matched on Zip)\n",
        "matched_zip = merged_zip[~merged_zip[\"SizeRank\"].isnull()].copy()\n",
        "\n",
        "# Secondary merge matches (matched on City+State)\n",
        "region_candidates = [c for c in merged_city.columns if \"RegionName\" in c]\n",
        "print(\"RegionName candidates in merged_city:\", region_candidates)\n",
        "\n",
        "# Pick dataset2's RegionName column\n",
        "region_col = next((c for c in region_candidates if c.endswith(\"_d2\") or c.endswith(\"_city\")), None)\n",
        "if region_col is None:\n",
        "    region_col = \"RegionName\"  # fallback\n",
        "\n",
        "matched_city = merged_city[~merged_city[region_col].isnull()].copy()\n",
        "unmatched_city = merged_city[merged_city[region_col].isnull()].copy()\n",
        "\n",
        "# Final combined dataset: Zip matches first, then City+State matches\n",
        "final_merged = pd.concat([matched_zip, matched_city], ignore_index=True)\n",
        "\n",
        "# Optional: reset index and drop temporary columns\n",
        "final_merged.reset_index(drop=True, inplace=True)\n",
        "for col in [\"city_state_clean_d1\", \"city_state_clean_d2\"]:\n",
        "    if col in final_merged.columns:\n",
        "        final_merged.drop(columns=[col], inplace=True)\n",
        "\n",
        "### --- Step 5: Print merge stats ---\n",
        "print(\"\\n--- Final Merge Results ---\")\n",
        "print(f\"Total rows in dataset1: {len(df_dataset1_processed)}\")\n",
        "print(f\"Matched on Zip: {len(matched_zip)}\")\n",
        "print(f\"Matched on City+State: {len(matched_city)}\")\n",
        "print(f\"Still unmatched after both merges: {len(unmatched_city)}\")\n",
        "print(f\"Final merged dataset shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC-jEhKOsFlV",
        "outputId": "6545c307-ab8d-4c65-e165-494f9cf5d85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegionName candidates in merged_city: ['RegionName_d1', 'RegionName_d2']\n",
            "\n",
            "--- Final Merge Results ---\n",
            "Total rows in dataset1: 8652\n",
            "Matched on Zip: 8036\n",
            "Matched on City+State: 0\n",
            "Still unmatched after both merges: 616\n",
            "Final merged dataset shape: (8036, 951)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task: Spatial Recovery using GeoPandas"
      ],
      "metadata": {
        "id": "T-Vj2u1l7qLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Spatial recovery for unmatched rows\n",
        "# ============================================\n",
        "\n",
        "# 0) Install & imports\n",
        "try:\n",
        "    import geopandas as gpd\n",
        "    from shapely.geometry import Point\n",
        "except Exception:\n",
        "    !pip install geopandas shapely pyproj --quiet\n",
        "    import geopandas as gpd\n",
        "    from shapely.geometry import Point\n",
        "\n",
        "try:\n",
        "    import pgeocode\n",
        "except Exception:\n",
        "    !pip install pgeocode --quiet\n",
        "    import pgeocode\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Choose our \"unmatched base\"\n",
        "# -----------------------------\n",
        "if 'unmatched_city' in locals() and unmatched_city is not None and len(unmatched_city) > 0:\n",
        "    unmatched_base = unmatched_city.copy()\n",
        "    print(f\"Using unmatched_city as base: {len(unmatched_base)} rows\")\n",
        "elif 'unmatched_zip' in locals() and unmatched_zip is not None and len(unmatched_zip) > 0:\n",
        "    unmatched_base = unmatched_zip.copy()\n",
        "    print(f\"Using unmatched_zip as base: {len(unmatched_base)} rows\")\n",
        "else:\n",
        "    unmatched_base = pd.DataFrame()\n",
        "    print(\"No unmatched rows to recover. Exiting spatial recovery.\")\n",
        "\n",
        "if unmatched_base.empty:\n",
        "    print(\"No unmatched rows to recover via spatial join. You're all set ✅\")\n",
        "else:\n",
        "    # --------------------------------------\n",
        "    # 2) Prepare Dataset2 ZIP centroids (lat/lng)\n",
        "    # --------------------------------------\n",
        "    df_dataset2_processed['RegionName'] = df_dataset2_processed['RegionName'].astype(str).str.zfill(5)\n",
        "    nomi = pgeocode.Nominatim('us')\n",
        "\n",
        "    unique_zips = df_dataset2_processed['RegionName'].dropna().unique().tolist()\n",
        "    z_meta = nomi.query_postal_code(unique_zips)\n",
        "    z_meta = z_meta[['postal_code', 'latitude', 'longitude']].rename(\n",
        "        columns={'postal_code': 'RegionName', 'latitude': 'lat', 'longitude': 'lng'}\n",
        "    )\n",
        "    z_meta['RegionName'] = z_meta['RegionName'].astype(str).str.zfill(5)\n",
        "\n",
        "    d2_with_xy = df_dataset2_processed.merge(z_meta, on='RegionName', how='left')\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 3) Build coordinates for unmatched_base (dataset1 side)\n",
        "    # --------------------------------------\n",
        "    d1 = unmatched_base.copy()\n",
        "\n",
        "    # Normalize Latitude/Longitude columns if present\n",
        "    lat_col = next((c for c in d1.columns if c.lower() == 'latitude'), None)\n",
        "    lng_col = next((c for c in d1.columns if c.lower() == 'longitude'), None)\n",
        "\n",
        "    d1['asset_lat'] = np.nan\n",
        "    d1['asset_lng'] = np.nan\n",
        "\n",
        "    if lat_col and lng_col:\n",
        "        d1.loc[~d1[lat_col].isna() & ~d1[lng_col].isna(), 'asset_lat'] = d1.loc[~d1[lat_col].isna() & ~d1[lng_col].isna(), lat_col]\n",
        "        d1.loc[~d1[lat_col].isna() & ~d1[lng_col].isna(), 'asset_lng'] = d1.loc[~d1[lat_col].isna() & ~d1[lng_col].isna(), lng_col]\n",
        "\n",
        "    # ZIP → centroid fallback\n",
        "    if 'Zip Code' in d1.columns:\n",
        "        d1['Zip Code'] = d1['Zip Code'].astype(str).str.zfill(5)\n",
        "        z1_meta = nomi.query_postal_code(d1['Zip Code'].tolist())\n",
        "\n",
        "        # Convert to Series aligned with d1's index\n",
        "        z1_lat = pd.Series(z1_meta['latitude'].values, index=d1.index)\n",
        "        z1_lng = pd.Series(z1_meta['longitude'].values, index=d1.index)\n",
        "\n",
        "        d1['asset_lat'] = d1['asset_lat'].fillna(z1_lat)\n",
        "        d1['asset_lng'] = d1['asset_lng'].fillna(z1_lng)\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 4) Build GeoDataFrames & nearest join\n",
        "    # --------------------------------------\n",
        "    have_xy = (~d1['asset_lat'].isna()) & (~d1['asset_lng'].isna())\n",
        "    print(f\"Assets ready for spatial match (have coords): {have_xy.sum()} / {len(d1)}\")\n",
        "\n",
        "    gdf_assets = gpd.GeoDataFrame(\n",
        "        d1.loc[have_xy].copy(),\n",
        "        geometry=gpd.points_from_xy(d1.loc[have_xy, 'asset_lng'], d1.loc[have_xy, 'asset_lat']),\n",
        "        crs='EPSG:4326'\n",
        "    )\n",
        "\n",
        "    gdf_ref = gpd.GeoDataFrame(\n",
        "        d2_with_xy.dropna(subset=['lat', 'lng']).copy(),\n",
        "        geometry=gpd.points_from_xy(d2_with_xy.dropna(subset=['lat', 'lng'])['lng'],\n",
        "                                    d2_with_xy.dropna(subset=['lat', 'lng'])['lat']),\n",
        "        crs='EPSG:4326'\n",
        "    )\n",
        "\n",
        "    gdf_assets = gdf_assets.to_crs(3857)\n",
        "    gdf_ref = gdf_ref.to_crs(3857)\n",
        "\n",
        "    gdf_spatial = gpd.sjoin_nearest(\n",
        "        gdf_assets, gdf_ref, how='left', distance_col='nearest_dist_m'\n",
        "    )\n",
        "\n",
        "    DIST_THRESHOLD_M = 30000\n",
        "    gdf_spatial_filt = gdf_spatial[gdf_spatial['nearest_dist_m'] <= DIST_THRESHOLD_M].copy()\n",
        "\n",
        "    print(\"Spatial recovered rows (within threshold):\", len(gdf_spatial_filt), \"/\", len(gdf_assets))\n",
        "    print(\"Distance (m) summary:\\n\", gdf_spatial_filt['nearest_dist_m'].describe())\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 5) Convert back to DataFrame & stitch\n",
        "    # --------------------------------------\n",
        "    spatial_recovered = pd.DataFrame(gdf_spatial_filt.drop(columns='geometry'))\n",
        "\n",
        "    # Previously matched datasets\n",
        "    matched_zip = merged_zip[~merged_zip['SizeRank'].isna()].copy() if 'merged_zip' in locals() else pd.DataFrame()\n",
        "    region_candidates = [c for c in merged_city.columns if 'RegionName' in c] if 'merged_city' in locals() else []\n",
        "    region_col = next((c for c in region_candidates if c.endswith('_d2') or c.endswith('_city')), None) if region_candidates else None\n",
        "    matched_city = merged_city[merged_city[region_col].notna()].copy() if region_col is not None else pd.DataFrame()\n",
        "\n",
        "    final_merged_spatial = pd.concat([matched_zip, matched_city, spatial_recovered], ignore_index=True)\n",
        "\n",
        "    print(\"\\n--- FINAL COUNTS ---\")\n",
        "    print(f\"Previously matched on Zip:        {len(matched_zip)}\")\n",
        "    print(f\"Previously matched on City+State: {len(matched_city)}\")\n",
        "    print(f\"Newly matched spatially:          {len(spatial_recovered)} (<= {DIST_THRESHOLD_M/1000:.0f} km)\")\n",
        "    still_unmatched_ct = len(unmatched_base) - len(spatial_recovered)\n",
        "    print(f\"Still unmatched after spatial:    {still_unmatched_ct}\")\n"
      ],
      "metadata": {
        "id": "Rtd_NWfOzq_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b508da9-36d2-4962-8667-24dbd7b13c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using unmatched_city as base: 616 rows\n",
            "Assets ready for spatial match (have coords): 616 / 616\n",
            "Spatial recovered rows (within threshold): 358 / 616\n",
            "Distance (m) summary:\n",
            " count      358.000000\n",
            "mean      4721.900895\n",
            "std       5552.532415\n",
            "min         62.061892\n",
            "25%       1353.916522\n",
            "50%       2818.638002\n",
            "75%       4711.981832\n",
            "max      27005.872834\n",
            "Name: nearest_dist_m, dtype: float64\n",
            "\n",
            "--- FINAL COUNTS ---\n",
            "Previously matched on Zip:        8036\n",
            "Previously matched on City+State: 0\n",
            "Newly matched spatially:          358 (<= 30 km)\n",
            "Still unmatched after spatial:    258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1) Drop columns that are completely blank (all NaN)\n",
        "# -----------------------------\n",
        "final_merged_cleaned = final_merged_spatial.dropna(axis=1, how=\"all\")\n",
        "\n",
        "dropped_cols_count = final_merged_spatial.shape[1] - final_merged_cleaned.shape[1]\n",
        "print(f\"Dropped {dropped_cols_count} columns with all blank values.\")\n",
        "print(f\"Remaining columns: {final_merged_cleaned.shape[1]}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Drop rows that still have no valuation match (i.e., SizeRank is missing)\n",
        "# -----------------------------\n",
        "if 'SizeRank' in final_merged_cleaned.columns:\n",
        "    final_merged_no_unmatched = final_merged_cleaned[final_merged_cleaned['SizeRank'].notna()].copy()\n",
        "    dropped_rows_count = final_merged_cleaned.shape[0] - final_merged_no_unmatched.shape[0]\n",
        "    print(f\"Dropped {dropped_rows_count} unmatched rows (SizeRank missing).\")\n",
        "    print(f\"Remaining rows: {final_merged_no_unmatched.shape[0]}\")\n",
        "else:\n",
        "    final_merged_no_unmatched = final_merged_cleaned.copy()\n",
        "    print(\"Warning: 'SizeRank' column not found. No rows dropped based on SizeRank.\")\n",
        "    print(f\"Remaining rows: {final_merged_no_unmatched.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvfWmVPrBE6r",
        "outputId": "10f5302e-2c15-42ed-a83a-3200e8c65dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 628 columns with all blank values.\n",
            "Remaining columns: 337\n",
            "Dropped 0 unmatched rows (SizeRank missing).\n",
            "Remaining rows: 8394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61600348",
        "outputId": "453d8697-5dbc-48d0-9759-1f4bbe297e83"
      },
      "source": [
        "if 'final_merged_no_unmatched' in locals() and final_merged_no_unmatched is not None:\n",
        "    print(\"Column names and their index numbers in final_merged_no_unmatched:\")\n",
        "    for i, col in enumerate(final_merged_no_unmatched.columns):\n",
        "        print(f\"Column Index {i}: {col}\")\n",
        "else:\n",
        "    print(\"The final_merged_no_unmatched DataFrame is not available.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names and their index numbers in final_merged_no_unmatched:\n",
            "Column Index 0: Owned or Leased\n",
            "Column Index 1: GSA Region\n",
            "Column Index 2: Street Address\n",
            "Column Index 3: City_d1\n",
            "Column Index 4: State_d1\n",
            "Column Index 5: Zip Code\n",
            "Column Index 6: Latitude\n",
            "Column Index 7: Longitude\n",
            "Column Index 8: Building Rentable Square Feet\n",
            "Column Index 9: Construction Date\n",
            "Column Index 10: Congressional District\n",
            "Column Index 11: Building Status\n",
            "Column Index 12: Real Property Asset Type\n",
            "Column Index 13: Building Age\n",
            "Column Index 14: SizeRank\n",
            "Column Index 15: RegionName\n",
            "Column Index 16: State_d2\n",
            "Column Index 17: City_d2\n",
            "Column Index 18: Metro\n",
            "Column Index 19: CountyName\n",
            "Column Index 20: 31-01-2000\n",
            "Column Index 21: 29-02-2000\n",
            "Column Index 22: 31-03-2000\n",
            "Column Index 23: 30-04-2000\n",
            "Column Index 24: 31-05-2000\n",
            "Column Index 25: 30-06-2000\n",
            "Column Index 26: 31-07-2000\n",
            "Column Index 27: 31-08-2000\n",
            "Column Index 28: 30-09-2000\n",
            "Column Index 29: 31-10-2000\n",
            "Column Index 30: 30-11-2000\n",
            "Column Index 31: 31-12-2000\n",
            "Column Index 32: 31-01-2001\n",
            "Column Index 33: 28-02-2001\n",
            "Column Index 34: 31-03-2001\n",
            "Column Index 35: 30-04-2001\n",
            "Column Index 36: 31-05-2001\n",
            "Column Index 37: 30-06-2001\n",
            "Column Index 38: 31-07-2001\n",
            "Column Index 39: 31-08-2001\n",
            "Column Index 40: 30-09-2001\n",
            "Column Index 41: 31-10-2001\n",
            "Column Index 42: 30-11-2001\n",
            "Column Index 43: 31-12-2001\n",
            "Column Index 44: 31-01-2002\n",
            "Column Index 45: 28-02-2002\n",
            "Column Index 46: 31-03-2002\n",
            "Column Index 47: 30-04-2002\n",
            "Column Index 48: 31-05-2002\n",
            "Column Index 49: 30-06-2002\n",
            "Column Index 50: 31-07-2002\n",
            "Column Index 51: 31-08-2002\n",
            "Column Index 52: 30-09-2002\n",
            "Column Index 53: 31-10-2002\n",
            "Column Index 54: 30-11-2002\n",
            "Column Index 55: 31-12-2002\n",
            "Column Index 56: 31-01-2003\n",
            "Column Index 57: 28-02-2003\n",
            "Column Index 58: 31-03-2003\n",
            "Column Index 59: 30-04-2003\n",
            "Column Index 60: 31-05-2003\n",
            "Column Index 61: 30-06-2003\n",
            "Column Index 62: 31-07-2003\n",
            "Column Index 63: 31-08-2003\n",
            "Column Index 64: 30-09-2003\n",
            "Column Index 65: 31-10-2003\n",
            "Column Index 66: 30-11-2003\n",
            "Column Index 67: 31-12-2003\n",
            "Column Index 68: 31-01-2004\n",
            "Column Index 69: 29-02-2004\n",
            "Column Index 70: 31-03-2004\n",
            "Column Index 71: 30-04-2004\n",
            "Column Index 72: 31-05-2004\n",
            "Column Index 73: 30-06-2004\n",
            "Column Index 74: 31-07-2004\n",
            "Column Index 75: 31-08-2004\n",
            "Column Index 76: 30-09-2004\n",
            "Column Index 77: 31-10-2004\n",
            "Column Index 78: 30-11-2004\n",
            "Column Index 79: 31-12-2004\n",
            "Column Index 80: 31-01-2005\n",
            "Column Index 81: 28-02-2005\n",
            "Column Index 82: 31-03-2005\n",
            "Column Index 83: 30-04-2005\n",
            "Column Index 84: 31-05-2005\n",
            "Column Index 85: 30-06-2005\n",
            "Column Index 86: 31-07-2005\n",
            "Column Index 87: 31-08-2005\n",
            "Column Index 88: 30-09-2005\n",
            "Column Index 89: 31-10-2005\n",
            "Column Index 90: 30-11-2005\n",
            "Column Index 91: 31-12-2005\n",
            "Column Index 92: 31-01-2006\n",
            "Column Index 93: 28-02-2006\n",
            "Column Index 94: 31-03-2006\n",
            "Column Index 95: 30-04-2006\n",
            "Column Index 96: 31-05-2006\n",
            "Column Index 97: 30-06-2006\n",
            "Column Index 98: 31-07-2006\n",
            "Column Index 99: 31-08-2006\n",
            "Column Index 100: 30-09-2006\n",
            "Column Index 101: 31-10-2006\n",
            "Column Index 102: 30-11-2006\n",
            "Column Index 103: 31-12-2006\n",
            "Column Index 104: 31-01-2007\n",
            "Column Index 105: 28-02-2007\n",
            "Column Index 106: 31-03-2007\n",
            "Column Index 107: 30-04-2007\n",
            "Column Index 108: 31-05-2007\n",
            "Column Index 109: 30-06-2007\n",
            "Column Index 110: 31-07-2007\n",
            "Column Index 111: 31-08-2007\n",
            "Column Index 112: 30-09-2007\n",
            "Column Index 113: 31-10-2007\n",
            "Column Index 114: 30-11-2007\n",
            "Column Index 115: 31-12-2007\n",
            "Column Index 116: 31-01-2008\n",
            "Column Index 117: 29-02-2008\n",
            "Column Index 118: 31-03-2008\n",
            "Column Index 119: 30-04-2008\n",
            "Column Index 120: 31-05-2008\n",
            "Column Index 121: 30-06-2008\n",
            "Column Index 122: 31-07-2008\n",
            "Column Index 123: 31-08-2008\n",
            "Column Index 124: 30-09-2008\n",
            "Column Index 125: 31-10-2008\n",
            "Column Index 126: 30-11-2008\n",
            "Column Index 127: 31-12-2008\n",
            "Column Index 128: 31-01-2009\n",
            "Column Index 129: 28-02-2009\n",
            "Column Index 130: 31-03-2009\n",
            "Column Index 131: 30-04-2009\n",
            "Column Index 132: 31-05-2009\n",
            "Column Index 133: 30-06-2009\n",
            "Column Index 134: 31-07-2009\n",
            "Column Index 135: 31-08-2009\n",
            "Column Index 136: 30-09-2009\n",
            "Column Index 137: 31-10-2009\n",
            "Column Index 138: 30-11-2009\n",
            "Column Index 139: 31-12-2009\n",
            "Column Index 140: 31-01-2010\n",
            "Column Index 141: 28-02-2010\n",
            "Column Index 142: 31-03-2010\n",
            "Column Index 143: 30-04-2010\n",
            "Column Index 144: 31-05-2010\n",
            "Column Index 145: 30-06-2010\n",
            "Column Index 146: 31-07-2010\n",
            "Column Index 147: 31-08-2010\n",
            "Column Index 148: 30-09-2010\n",
            "Column Index 149: 31-10-2010\n",
            "Column Index 150: 30-11-2010\n",
            "Column Index 151: 31-12-2010\n",
            "Column Index 152: 31-01-2011\n",
            "Column Index 153: 28-02-2011\n",
            "Column Index 154: 31-03-2011\n",
            "Column Index 155: 30-04-2011\n",
            "Column Index 156: 31-05-2011\n",
            "Column Index 157: 30-06-2011\n",
            "Column Index 158: 31-07-2011\n",
            "Column Index 159: 31-08-2011\n",
            "Column Index 160: 30-09-2011\n",
            "Column Index 161: 31-10-2011\n",
            "Column Index 162: 30-11-2011\n",
            "Column Index 163: 31-12-2011\n",
            "Column Index 164: 31-01-2012\n",
            "Column Index 165: 29-02-2012\n",
            "Column Index 166: 31-03-2012\n",
            "Column Index 167: 30-04-2012\n",
            "Column Index 168: 31-05-2012\n",
            "Column Index 169: 30-06-2012\n",
            "Column Index 170: 31-07-2012\n",
            "Column Index 171: 31-08-2012\n",
            "Column Index 172: 30-09-2012\n",
            "Column Index 173: 31-10-2012\n",
            "Column Index 174: 30-11-2012\n",
            "Column Index 175: 31-12-2012\n",
            "Column Index 176: 31-01-2013\n",
            "Column Index 177: 28-02-2013\n",
            "Column Index 178: 31-03-2013\n",
            "Column Index 179: 30-04-2013\n",
            "Column Index 180: 31-05-2013\n",
            "Column Index 181: 30-06-2013\n",
            "Column Index 182: 31-07-2013\n",
            "Column Index 183: 31-08-2013\n",
            "Column Index 184: 30-09-2013\n",
            "Column Index 185: 31-10-2013\n",
            "Column Index 186: 30-11-2013\n",
            "Column Index 187: 31-12-2013\n",
            "Column Index 188: 31-01-2014\n",
            "Column Index 189: 28-02-2014\n",
            "Column Index 190: 31-03-2014\n",
            "Column Index 191: 30-04-2014\n",
            "Column Index 192: 31-05-2014\n",
            "Column Index 193: 30-06-2014\n",
            "Column Index 194: 31-07-2014\n",
            "Column Index 195: 31-08-2014\n",
            "Column Index 196: 30-09-2014\n",
            "Column Index 197: 31-10-2014\n",
            "Column Index 198: 30-11-2014\n",
            "Column Index 199: 31-12-2014\n",
            "Column Index 200: 31-01-2015\n",
            "Column Index 201: 28-02-2015\n",
            "Column Index 202: 31-03-2015\n",
            "Column Index 203: 30-04-2015\n",
            "Column Index 204: 31-05-2015\n",
            "Column Index 205: 30-06-2015\n",
            "Column Index 206: 31-07-2015\n",
            "Column Index 207: 31-08-2015\n",
            "Column Index 208: 30-09-2015\n",
            "Column Index 209: 31-10-2015\n",
            "Column Index 210: 30-11-2015\n",
            "Column Index 211: 31-12-2015\n",
            "Column Index 212: 31-01-2016\n",
            "Column Index 213: 29-02-2016\n",
            "Column Index 214: 31-03-2016\n",
            "Column Index 215: 30-04-2016\n",
            "Column Index 216: 31-05-2016\n",
            "Column Index 217: 30-06-2016\n",
            "Column Index 218: 31-07-2016\n",
            "Column Index 219: 31-08-2016\n",
            "Column Index 220: 30-09-2016\n",
            "Column Index 221: 31-10-2016\n",
            "Column Index 222: 30-11-2016\n",
            "Column Index 223: 31-12-2016\n",
            "Column Index 224: 31-01-2017\n",
            "Column Index 225: 28-02-2017\n",
            "Column Index 226: 31-03-2017\n",
            "Column Index 227: 30-04-2017\n",
            "Column Index 228: 31-05-2017\n",
            "Column Index 229: 30-06-2017\n",
            "Column Index 230: 31-07-2017\n",
            "Column Index 231: 31-08-2017\n",
            "Column Index 232: 30-09-2017\n",
            "Column Index 233: 31-10-2017\n",
            "Column Index 234: 30-11-2017\n",
            "Column Index 235: 31-12-2017\n",
            "Column Index 236: 31-01-2018\n",
            "Column Index 237: 28-02-2018\n",
            "Column Index 238: 31-03-2018\n",
            "Column Index 239: 30-04-2018\n",
            "Column Index 240: 31-05-2018\n",
            "Column Index 241: 30-06-2018\n",
            "Column Index 242: 31-07-2018\n",
            "Column Index 243: 31-08-2018\n",
            "Column Index 244: 30-09-2018\n",
            "Column Index 245: 31-10-2018\n",
            "Column Index 246: 30-11-2018\n",
            "Column Index 247: 31-12-2018\n",
            "Column Index 248: 31-01-2019\n",
            "Column Index 249: 28-02-2019\n",
            "Column Index 250: 31-03-2019\n",
            "Column Index 251: 30-04-2019\n",
            "Column Index 252: 31-05-2019\n",
            "Column Index 253: 30-06-2019\n",
            "Column Index 254: 31-07-2019\n",
            "Column Index 255: 31-08-2019\n",
            "Column Index 256: 30-09-2019\n",
            "Column Index 257: 31-10-2019\n",
            "Column Index 258: 30-11-2019\n",
            "Column Index 259: 31-12-2019\n",
            "Column Index 260: 31-01-2020\n",
            "Column Index 261: 29-02-2020\n",
            "Column Index 262: 31-03-2020\n",
            "Column Index 263: 30-04-2020\n",
            "Column Index 264: 31-05-2020\n",
            "Column Index 265: 30-06-2020\n",
            "Column Index 266: 31-07-2020\n",
            "Column Index 267: 31-08-2020\n",
            "Column Index 268: 30-09-2020\n",
            "Column Index 269: 31-10-2020\n",
            "Column Index 270: 30-11-2020\n",
            "Column Index 271: 31-12-2020\n",
            "Column Index 272: 31-01-2021\n",
            "Column Index 273: 28-02-2021\n",
            "Column Index 274: 31-03-2021\n",
            "Column Index 275: 30-04-2021\n",
            "Column Index 276: 31-05-2021\n",
            "Column Index 277: 30-06-2021\n",
            "Column Index 278: 31-07-2021\n",
            "Column Index 279: 31-08-2021\n",
            "Column Index 280: 30-09-2021\n",
            "Column Index 281: 31-10-2021\n",
            "Column Index 282: 30-11-2021\n",
            "Column Index 283: 31-12-2021\n",
            "Column Index 284: 31-01-2022\n",
            "Column Index 285: 28-02-2022\n",
            "Column Index 286: 31-03-2022\n",
            "Column Index 287: 30-04-2022\n",
            "Column Index 288: 31-05-2022\n",
            "Column Index 289: 30-06-2022\n",
            "Column Index 290: 31-07-2022\n",
            "Column Index 291: 31-08-2022\n",
            "Column Index 292: 30-09-2022\n",
            "Column Index 293: 31-10-2022\n",
            "Column Index 294: 30-11-2022\n",
            "Column Index 295: 31-12-2022\n",
            "Column Index 296: 31-01-2023\n",
            "Column Index 297: 28-02-2023\n",
            "Column Index 298: 31-03-2023\n",
            "Column Index 299: 30-04-2023\n",
            "Column Index 300: 31-05-2023\n",
            "Column Index 301: 30-06-2023\n",
            "Column Index 302: 31-07-2023\n",
            "Column Index 303: 31-08-2023\n",
            "Column Index 304: 30-09-2023\n",
            "Column Index 305: 31-10-2023\n",
            "Column Index 306: 30-11-2023\n",
            "Column Index 307: 31-12-2023\n",
            "Column Index 308: 31-01-2024\n",
            "Column Index 309: 29-02-2024\n",
            "Column Index 310: 31-03-2024\n",
            "Column Index 311: 30-04-2024\n",
            "Column Index 312: 31-05-2024\n",
            "Column Index 313: 30-06-2024\n",
            "Column Index 314: 31-07-2024\n",
            "Column Index 315: 31-08-2024\n",
            "Column Index 316: 30-09-2024\n",
            "Column Index 317: 31-10-2024\n",
            "Column Index 318: 30-11-2024\n",
            "Column Index 319: 31-12-2024\n",
            "Column Index 320: 31-01-2025\n",
            "Column Index 321: 28-02-2025\n",
            "Column Index 322: 31-03-2025\n",
            "Column Index 323: 30-04-2025\n",
            "Column Index 324: 31-05-2025\n",
            "Column Index 325: 30-06-2025\n",
            "Column Index 326: 31-07-2025\n",
            "Column Index 327: city_state_clean_d1\n",
            "Column Index 328: asset_lat\n",
            "Column Index 329: asset_lng\n",
            "Column Index 330: index_right\n",
            "Column Index 331: State_right\n",
            "Column Index 332: City_right\n",
            "Column Index 333: city_state_clean_d2_right\n",
            "Column Index 334: lat\n",
            "Column Index 335: lng\n",
            "Column Index 336: nearest_dist_m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97adb151",
        "outputId": "add8a463-ed21-4d26-8bb3-60b9063d0711"
      },
      "source": [
        "if 'final_merged_no_unmatched' in locals() and final_merged_no_unmatched is not None:\n",
        "    print(\"--- Info for final_merged_no_unmatched ---\")\n",
        "    final_merged_no_unmatched.info()\n",
        "else:\n",
        "    print(\"final_merged_no_unmatched DataFrame is not available.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Info for final_merged_no_unmatched ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8394 entries, 0 to 8393\n",
            "Columns: 337 entries, Owned or Leased to nearest_dist_m\n",
            "dtypes: float64(325), int64(7), object(5)\n",
            "memory usage: 21.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0785e3d",
        "outputId": "937a942b-617c-4350-e36a-35ab25caf098"
      },
      "source": [
        "if 'final_merged_no_unmatched' in locals() and final_merged_no_unmatched is not None:\n",
        "    print(\"--- Dropping columns with all blank values from final_merged_no_unmatched ---\")\n",
        "    # Drop columns where all values are NaN\n",
        "    final_merged_spatial_cleaned = final_merged_no_unmatched.dropna(axis=1, how='all')\n",
        "\n",
        "    print(f\"Original number of columns: {final_merged_no_unmatched.shape[1]}\")\n",
        "    print(f\"Number of columns after dropping blank columns: {final_merged_spatial_cleaned.shape[1]}\")\n",
        "\n",
        "    # Update the final_merged_spatial variable if you want to continue working with the cleaned data\n",
        "    final_merged_spatial = final_merged_spatial_cleaned\n",
        "    print(\"Updated final_merged_spatial with the cleaned DataFrame.\")\n",
        "\n",
        "else:\n",
        "    print(\"final_merged_spatial DataFrame is not available. Cannot perform this operation.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dropping columns with all blank values from final_merged_no_unmatched ---\n",
            "Original number of columns: 337\n",
            "Number of columns after dropping blank columns: 337\n",
            "Updated final_merged_spatial with the cleaned DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6e9276",
        "outputId": "b8848a3a-17b7-435f-dd56-7fff47311d4f"
      },
      "source": [
        "if 'final_merged_spatial' in locals() and final_merged_spatial is not None:\n",
        "    print(\"--- Selecting columns from 'Owned or Leased' to '31-07-2025' ---\")\n",
        "\n",
        "    # Get the list of all columns\n",
        "    all_columns = final_merged_spatial.columns.tolist()\n",
        "\n",
        "    try:\n",
        "        # Find the index of the start and end columns\n",
        "        start_index = all_columns.index('Owned or Leased')\n",
        "        end_index = all_columns.index('31-07-2025')\n",
        "\n",
        "        # Select the columns within the specified range (inclusive of the end index)\n",
        "        columns_to_keep = all_columns[start_index : end_index + 1]\n",
        "\n",
        "        # Create a new DataFrame with only the selected columns\n",
        "        final_merged_spatial_subset = final_merged_spatial[columns_to_keep].copy()\n",
        "\n",
        "        print(f\"Original number of columns: {final_merged_spatial.shape[1]}\")\n",
        "        print(f\"Number of columns after selecting the range: {final_merged_spatial_subset.shape[1]}\")\n",
        "\n",
        "        # Update the final_merged_spatial variable to the subset\n",
        "        final_merged_spatial = final_merged_spatial_subset\n",
        "        print(\"Updated final_merged_spatial to include only the selected columns.\")\n",
        "\n",
        "        print(\"\\n--- Columns in the updated final_merged_spatial ---\")\n",
        "        print(final_merged_spatial.columns.tolist())\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: One of the specified columns was not found in the DataFrame: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"final_merged_spatial DataFrame is not available. Cannot perform this operation.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Selecting columns from 'Owned or Leased' to '31-07-2025' ---\n",
            "Original number of columns: 337\n",
            "Number of columns after selecting the range: 327\n",
            "Updated final_merged_spatial to include only the selected columns.\n",
            "\n",
            "--- Columns in the updated final_merged_spatial ---\n",
            "['Owned or Leased', 'GSA Region', 'Street Address', 'City_d1', 'State_d1', 'Zip Code', 'Latitude', 'Longitude', 'Building Rentable Square Feet', 'Construction Date', 'Congressional District', 'Building Status', 'Real Property Asset Type', 'Building Age', 'SizeRank', 'RegionName', 'State_d2', 'City_d2', 'Metro', 'CountyName', '31-01-2000', '29-02-2000', '31-03-2000', '30-04-2000', '31-05-2000', '30-06-2000', '31-07-2000', '31-08-2000', '30-09-2000', '31-10-2000', '30-11-2000', '31-12-2000', '31-01-2001', '28-02-2001', '31-03-2001', '30-04-2001', '31-05-2001', '30-06-2001', '31-07-2001', '31-08-2001', '30-09-2001', '31-10-2001', '30-11-2001', '31-12-2001', '31-01-2002', '28-02-2002', '31-03-2002', '30-04-2002', '31-05-2002', '30-06-2002', '31-07-2002', '31-08-2002', '30-09-2002', '31-10-2002', '30-11-2002', '31-12-2002', '31-01-2003', '28-02-2003', '31-03-2003', '30-04-2003', '31-05-2003', '30-06-2003', '31-07-2003', '31-08-2003', '30-09-2003', '31-10-2003', '30-11-2003', '31-12-2003', '31-01-2004', '29-02-2004', '31-03-2004', '30-04-2004', '31-05-2004', '30-06-2004', '31-07-2004', '31-08-2004', '30-09-2004', '31-10-2004', '30-11-2004', '31-12-2004', '31-01-2005', '28-02-2005', '31-03-2005', '30-04-2005', '31-05-2005', '30-06-2005', '31-07-2005', '31-08-2005', '30-09-2005', '31-10-2005', '30-11-2005', '31-12-2005', '31-01-2006', '28-02-2006', '31-03-2006', '30-04-2006', '31-05-2006', '30-06-2006', '31-07-2006', '31-08-2006', '30-09-2006', '31-10-2006', '30-11-2006', '31-12-2006', '31-01-2007', '28-02-2007', '31-03-2007', '30-04-2007', '31-05-2007', '30-06-2007', '31-07-2007', '31-08-2007', '30-09-2007', '31-10-2007', '30-11-2007', '31-12-2007', '31-01-2008', '29-02-2008', '31-03-2008', '30-04-2008', '31-05-2008', '30-06-2008', '31-07-2008', '31-08-2008', '30-09-2008', '31-10-2008', '30-11-2008', '31-12-2008', '31-01-2009', '28-02-2009', '31-03-2009', '30-04-2009', '31-05-2009', '30-06-2009', '31-07-2009', '31-08-2009', '30-09-2009', '31-10-2009', '30-11-2009', '31-12-2009', '31-01-2010', '28-02-2010', '31-03-2010', '30-04-2010', '31-05-2010', '30-06-2010', '31-07-2010', '31-08-2010', '30-09-2010', '31-10-2010', '30-11-2010', '31-12-2010', '31-01-2011', '28-02-2011', '31-03-2011', '30-04-2011', '31-05-2011', '30-06-2011', '31-07-2011', '31-08-2011', '30-09-2011', '31-10-2011', '30-11-2011', '31-12-2011', '31-01-2012', '29-02-2012', '31-03-2012', '30-04-2012', '31-05-2012', '30-06-2012', '31-07-2012', '31-08-2012', '30-09-2012', '31-10-2012', '30-11-2012', '31-12-2012', '31-01-2013', '28-02-2013', '31-03-2013', '30-04-2013', '31-05-2013', '30-06-2013', '31-07-2013', '31-08-2013', '30-09-2013', '31-10-2013', '30-11-2013', '31-12-2013', '31-01-2014', '28-02-2014', '31-03-2014', '30-04-2014', '31-05-2014', '30-06-2014', '31-07-2014', '31-08-2014', '30-09-2014', '31-10-2014', '30-11-2014', '31-12-2014', '31-01-2015', '28-02-2015', '31-03-2015', '30-04-2015', '31-05-2015', '30-06-2015', '31-07-2015', '31-08-2015', '30-09-2015', '31-10-2015', '30-11-2015', '31-12-2015', '31-01-2016', '29-02-2016', '31-03-2016', '30-04-2016', '31-05-2016', '30-06-2016', '31-07-2016', '31-08-2016', '30-09-2016', '31-10-2016', '30-11-2016', '31-12-2016', '31-01-2017', '28-02-2017', '31-03-2017', '30-04-2017', '31-05-2017', '30-06-2017', '31-07-2017', '31-08-2017', '30-09-2017', '31-10-2017', '30-11-2017', '31-12-2017', '31-01-2018', '28-02-2018', '31-03-2018', '30-04-2018', '31-05-2018', '30-06-2018', '31-07-2018', '31-08-2018', '30-09-2018', '31-10-2018', '30-11-2018', '31-12-2018', '31-01-2019', '28-02-2019', '31-03-2019', '30-04-2019', '31-05-2019', '30-06-2019', '31-07-2019', '31-08-2019', '30-09-2019', '31-10-2019', '30-11-2019', '31-12-2019', '31-01-2020', '29-02-2020', '31-03-2020', '30-04-2020', '31-05-2020', '30-06-2020', '31-07-2020', '31-08-2020', '30-09-2020', '31-10-2020', '30-11-2020', '31-12-2020', '31-01-2021', '28-02-2021', '31-03-2021', '30-04-2021', '31-05-2021', '30-06-2021', '31-07-2021', '31-08-2021', '30-09-2021', '31-10-2021', '30-11-2021', '31-12-2021', '31-01-2022', '28-02-2022', '31-03-2022', '30-04-2022', '31-05-2022', '30-06-2022', '31-07-2022', '31-08-2022', '30-09-2022', '31-10-2022', '30-11-2022', '31-12-2022', '31-01-2023', '28-02-2023', '31-03-2023', '30-04-2023', '31-05-2023', '30-06-2023', '31-07-2023', '31-08-2023', '30-09-2023', '31-10-2023', '30-11-2023', '31-12-2023', '31-01-2024', '29-02-2024', '31-03-2024', '30-04-2024', '31-05-2024', '30-06-2024', '31-07-2024', '31-08-2024', '30-09-2024', '31-10-2024', '30-11-2024', '31-12-2024', '31-01-2025', '28-02-2025', '31-03-2025', '30-04-2025', '31-05-2025', '30-06-2025', '31-07-2025']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'final_merged_spatial' in locals() and final_merged_spatial is not None:\n",
        "    output_path = '/content/drive/MyDrive/RWAP/final_merged_spatial.csv'\n",
        "    try:\n",
        "        final_merged_spatial.to_csv(output_path, index=False)\n",
        "        print(f\"Successfully saved final_merged_spatial to {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving the file: {e}\")\n",
        "else:\n",
        "    print(\"final_merged_spatial DataFrame is not available. Cannot save the file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76B1RGmjZA3P",
        "outputId": "9d6f6c69-8502-4212-80ac-b4c62429b382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved final_merged_spatial to /content/drive/MyDrive/RWAP/final_merged_spatial.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "712d20a4",
        "outputId": "3929fd8b-25d3-4653-dba4-695c9a16f5aa"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Specify the path to the saved file\n",
        "output_path = '/content/drive/MyDrive/RWAP/final_merged_spatial.csv'\n",
        "\n",
        "try:\n",
        "    files.download(output_path)\n",
        "    print(f\"Attempting to download {output_path}...\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {output_path}. Please ensure the file exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during download: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af7d6bb3-5098-4ef5-8954-3d32f5e2fe4c\", \"final_merged_spatial.csv\", 28568016)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download /content/drive/MyDrive/RWAP/final_merged_spatial.csv...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'final_merged_spatial' in locals() and final_merged_spatial is not None:\n",
        "    print(\"--- Info for final_merged_spatial ---\")\n",
        "    final_merged_spatial.info()\n",
        "else:\n",
        "    print(\"final_merged_spatial DataFrame is not available.\")"
      ],
      "metadata": {
        "id": "OM9OHIwvgkj0",
        "outputId": "1345f3f2-d316-492f-ddc2-31652dfc83a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Info for final_merged_spatial ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8394 entries, 0 to 8393\n",
            "Columns: 327 entries, Owned or Leased to 31-07-2025\n",
            "dtypes: float64(317), int64(7), object(3)\n",
            "memory usage: 20.9+ MB\n"
          ]
        }
      ]
    }
  ]
}